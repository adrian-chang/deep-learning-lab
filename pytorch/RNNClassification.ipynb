{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name Classifiaction\n",
    "\n",
    "Take the result of putting the entire name in, and predict a softmax of what country the name belongs do\n",
    "\n",
    "* All letters are used to generated one output instead of each letter producting an output\n",
    "* Input has to cover the entire space ... use all rnn is as large as there are characters, use 20 characters, 20 inputs etc.\n",
    "    * char -> ascii (size of all possible characters) -> embedding (size of rnn input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2ascii_arr(name):\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention\n",
    "\n",
    "* Focus on different parts of the encoding RNN's output (foreign language words, each 1 as 1 input into an RNN)\n",
    "    * The primary idea is that the `next` decoding output could bounce around the encoding put, economic zone, instead of trying to output the translation for economic, output zone first given the meaning of the input and the output target\n",
    "* Economic -> Focus on economic sounding words\n",
    "* https://distill.pub/2016/augmented-rnns/\n",
    "* Input is a single vector, output is word by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(t.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = t.nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = t.nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.fc = t.nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        input = input.t()\n",
    "        print(f'input {input.size()}')\n",
    "        embedded = self.embedding(input)\n",
    "        print(f'embedding {embedded.size()}')\n",
    "        hidden = self._init_hidden(batch_size)\n",
    "        output, hidden = self.gru(embedded, hidden) # last output is same as hidden\n",
    "        print(f'gru hidden output {hidden.size()}')\n",
    "        fc_output = self.fc(hidden)\n",
    "        print(f'fc output {fc_output.size()}')\n",
    "        return fc_output\n",
    "    def _init_hidden(self, batch_size):\n",
    "        return t.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([6, 1])\n",
      "embedding torch.Size([6, 1, 100])\n",
      "gru hidden output torch.Size([1, 1, 100])\n",
      "fc output torch.Size([1, 1, 18])\n",
      "in torch.Size([1, 6]) out torch.Size([1, 1, 18])\n",
      "input torch.Size([5, 1])\n",
      "embedding torch.Size([5, 1, 100])\n",
      "gru hidden output torch.Size([1, 1, 100])\n",
      "fc output torch.Size([1, 1, 18])\n",
      "in torch.Size([1, 5]) out torch.Size([1, 1, 18])\n",
      "input torch.Size([4, 1])\n",
      "embedding torch.Size([4, 1, 100])\n",
      "gru hidden output torch.Size([1, 1, 100])\n",
      "fc output torch.Size([1, 1, 18])\n",
      "in torch.Size([1, 4]) out torch.Size([1, 1, 18])\n",
      "input torch.Size([3, 1])\n",
      "embedding torch.Size([3, 1, 100])\n",
      "gru hidden output torch.Size([1, 1, 100])\n",
      "fc output torch.Size([1, 1, 18])\n",
      "in torch.Size([1, 3]) out torch.Size([1, 1, 18])\n",
      "input torch.Size([6, 4])\n",
      "embedding torch.Size([6, 4, 100])\n",
      "gru hidden output torch.Size([1, 4, 100])\n",
      "fc output torch.Size([1, 4, 18])\n",
      "batch in torch.Size([4, 6]) batch out torch.Size([1, 4, 18])\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_SIZE = 100\n",
    "N_CHARS = 128  # ASCII\n",
    "N_CLASSES = 18\n",
    "\n",
    "# pad sequences and sort the tensor\n",
    "def pad_sequences(vectorized_seqs, seq_lengths):\n",
    "    seq_tensor = t.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = t.LongTensor(seq)\n",
    "    return seq_tensor\n",
    "\n",
    "# Create necessary variables, lengths, and target\n",
    "def make_variables(names):\n",
    "    sequence_and_length = [str2ascii_arr(name) for name in names]\n",
    "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
    "    seq_lengths = t.LongTensor([sl[1] for sl in sequence_and_length])\n",
    "    return pad_sequences(vectorized_seqs, seq_lengths)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    names = ['adylov', 'solan', 'hard', 'san']\n",
    "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_CLASSES)\n",
    "\n",
    "    for name in names:\n",
    "        arr, _ = str2ascii_arr(name)\n",
    "        inp = t.LongTensor([arr])\n",
    "        out = classifier(inp)\n",
    "        print(\"in\", inp.size(), \"out\", out.size())\n",
    "\n",
    "    inputs = make_variables(names)\n",
    "    out = classifier(inputs)\n",
    "    print(\"batch in\", inputs.size(), \"batch out\", out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements\n",
    "\n",
    "* Pack in / out to use 1 large efficient matrix\n",
    "* Use CUDA / GPUs\n",
    "    * Variables\n",
    "    * Models\n",
    "* Make data in parallel (multiple GPUs)\n",
    "    * `nn.DataParallel`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
