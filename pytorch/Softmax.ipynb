{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Outputs\n",
    "\n",
    "$ XW = \\hat{y} $\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "  a_1 & b_1\\\\\n",
    "  a_2 & b_2 \\\\\n",
    "  ... \\\\\n",
    "  a_n & b_n\n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "w_1 ...  w_{10} \\\\ w_{11} ... w_{20}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    " y_1 ... y_{10} \\\\\n",
    " ... \\\\\n",
    " y_n ... y_{10n}\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\sigma(z)_j = \\frac{e^{z_j}}{\\sum_{k=1}^{K} e^{z_k}} \\forall j = 1, ... k\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use output as probability, softmax is like sigmoid that fits between 0 / 1, probablilty of output occuring\n",
    "\n",
    "Takes a linear output first, then softmax transforms the linear output (logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross entropy is the loss\n",
    "\n",
    "$D(\\hat{y}, y) = -ylog(\\hat{y})$\n",
    "\n",
    "$\\alpha = \\frac{1}{n} \\sum_{i} D(\\sigma(wx_i + b), y_i) $ (Sum of loss) (sigma is softmax function)\n",
    "\n",
    "$\\hat{y} = wx_i + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1 = 0.35667494393873245\n",
      "loss 2 = 2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "Y = np.array([1, 0, 0])\n",
    "Y_pred1 = np.array([0.7, 0.2, 0.1]) # generated by the sigma function, softmax values\n",
    "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
    "\n",
    "print(f\"loss 1 = {np.sum(-Y * np.log(Y_pred1))}\")\n",
    "print(f\"loss 2 = {np.sum(-Y * np.log(Y_pred2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = t.Tensor([0]).long() # needs to not be 1 hot but input, 0, 1, or 2, a singular class\n",
    "Y_pred1 = t.Tensor([[2.0, 1.0, 0.1]])\n",
    "Y_pred2 = t.Tensor([[0.5, 2.0, 0.3]])\n",
    "l1 = loss(Y_pred1, Y) # feed logit values directly, cross entropy loss has log softmax in it\n",
    "l2 = loss(Y_pred2, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1 = 0.41703000664711\n",
      "loss 2 = 1.840616226196289\n"
     ]
    }
   ],
   "source": [
    "print(f\"loss 1 = {l1.item()}\")\n",
    "print(f\"loss 2 = {l2.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1 = 0.4966353476047516\n",
      "loss 2 = 1.2388995885849\n"
     ]
    }
   ],
   "source": [
    "# classes\n",
    "Y = t.Tensor([2, 0, 1]).long()\n",
    "# logits\n",
    "Y_pred1 = t.Tensor([\n",
    "    [0.1, 0.2, 0.9],\n",
    "    [1.1, 0.1, 0.2],\n",
    "    [0.2, 2.1, 0.1]\n",
    "])\n",
    "Y_pred2 = t.Tensor([\n",
    "    [0.8, 0.2, 0.3],\n",
    "    [0.2, 0.3, 0.5],\n",
    "    [0.2, 0.2, 0.5]\n",
    "])\n",
    "l1 = loss(Y_pred1, Y)\n",
    "l2 = loss(Y_pred2, Y)\n",
    "print(f\"loss 1 = {l1.item()}\")\n",
    "print(f\"loss 2 = {l2.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/49390842/cross-entropy-in-pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jamesmccaffrey.wordpress.com/2016/09/25/log-loss-and-cross-entropy-are-almost-the-same/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1898,  0.1717,  0.1717,  0.4668]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nn.Softmax(dim=1)(t.Tensor([[0.1, 0, 0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7619)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(t.Tensor([[0.1, 0, 0, 1]]), t.Tensor([3]).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear output [0.1,0,0,1] is transformed into probabilities (sums to 1), where the class dictates which label (0-3) should be the label of an instance, class should be 3 (3rd column), therefore, loss is -1 + log(exp(0.1) + exp(0) + exp(0) + exp(1)) which is = 0.7619\n",
    "\n",
    "The key idea here is saying, the biggest number leads to the largest log probability, meaning we want the class to match of the column with the biggest number otherwise loss (error) is high, and the other columns to have much smaller numbers than the class column otherwise our confidence is not great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same ways to calculate loss by hand (same result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logits, -1 is the logit of class 3 (3rd column value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618933412552511"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 + np.log(np.exp(0.1) + np.exp(0) + np.exp(0) + np.exp(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using probabilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7618543785697361"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 * np.log(0.4668)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://willwolf.io/2017/05/18/minimizing_the_negative_log_likelihood_in_english/\n",
    "\n",
    "BCE for logistic regression (binary probabilities)\n",
    "CE for softmax (multi class probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/master/nn.html?highlight=nllloss\n",
    "\n",
    "LogSoftMax + NLLLoss is CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(t.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784) # -1 mean dim is inferred from 28 x 28, flattened\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x) # just net outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = t.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = t.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304789\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.299541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achang/miniconda2/envs/deep-learning-lab/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.296423\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.306162\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.299385\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.298890\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.303989\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.306057\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.304603\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.283331\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.295969\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.303003\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.298502\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.305266\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.301448\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.295375\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.293651\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.293951\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.286144\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.297590\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.306946\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.286249\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.296256\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.293067\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.291368\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.295847\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.292334\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.295979\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.299374\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.295809\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.295408\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.288013\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.289765\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.292668\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.288237\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.284949\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.274853\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.291941\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.289378\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.284346\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.286236\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.286299\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.295378\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.296379\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.275323\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.285683\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.284606\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.270307\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.280625\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.274360\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.278199\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.271560\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.282483\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.275189\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.270378\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.263346\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.270151\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.271453\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.271656\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.264207\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.265773\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.260484\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.259610\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.260228\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.256489\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.252440\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.243304\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.242424\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.238304\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.255563\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.228037\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.222317\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.219157\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.222561\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.206729\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.191676\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.202015\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.169376\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.159460\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.169141\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.166969\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.115860\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.134079\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 2.077353\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.062060\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.976923\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.072888\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.993738\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.026263\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.993394\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.838161\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.856210\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.746667\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.765924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/achang/miniconda2/envs/deep-learning-lab/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0261, Accuracy: 5546/10000 (55%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.660447\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.581270\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.474143\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.419178\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.381595\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.268142\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.273358\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.019283\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.079076\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.134149\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.151120\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.904954\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.006719\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.875994\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.961699\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.883651\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.890092\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.913467\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.684347\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.893164\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.790607\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.808746\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.769128\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.919881\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.713157\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.721568\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.766638\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.698101\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.649349\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.629939\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.614875\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.844475\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.805753\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.563868\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.725954\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.668562\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.464866\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.654549\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.503787\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.849936\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.686840\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.651623\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.650885\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.666674\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.591073\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.624295\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.794093\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.535085\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.587576\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.663774\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.653921\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.518427\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.701365\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.610707\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.719223\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.531685\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.625094\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.535109\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.587300\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.554863\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.861486\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.438431\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.419302\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.409137\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.473919\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.616693\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.603211\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.557251\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.588921\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.428432\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.474807\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.476550\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.564007\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.652230\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.605202\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.517187\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.692073\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.469547\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.343794\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.401524\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.336594\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.681598\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.446680\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.559679\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.363702\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.375402\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.873708\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.434468\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.475998\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.355916\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.488565\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.245938\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.518527\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.486642\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8688/10000 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.445698\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.240283\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.410365\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.303199\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.293974\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.212012\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.507448\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.558874\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.494414\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.359525\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.450694\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.459189\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.433307\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.407679\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.269370\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.394515\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.289807\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.399117\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.346768\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.362169\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.475178\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.541782\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.337134\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.315589\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.677220\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.255127\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.289208\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.398229\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.340482\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.247654\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.155839\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.282675\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.600317\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.263954\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.649789\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.684445\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.406225\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.267558\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.404289\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.453272\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.390896\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.239755\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.313276\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.430828\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.487874\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.436944\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.385679\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.322672\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.292457\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.359478\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.366717\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.215663\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.374226\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.208447\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.542936\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.311691\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.437035\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.354623\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.463771\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.313306\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.273295\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.212761\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.252534\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.229111\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.315913\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.269923\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.347635\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.262008\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.397428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.357668\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.322899\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.215671\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.276258\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.518217\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.207444\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.211908\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.219625\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.265137\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.479460\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.403197\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.544296\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.209254\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.247154\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.191890\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.446884\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.303397\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.256822\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.515997\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.268607\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.351587\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.342261\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.188130\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.374930\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.318204\n",
      "\n",
      "Test set: Average loss: 0.0047, Accuracy: 9107/10000 (91%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.332494\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.185136\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.201239\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.275067\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.202713\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.207580\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.263349\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.145425\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.265050\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.462376\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.200194\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.378639\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.269897\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.225053\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.315267\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.506289\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.403077\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.467991\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.140482\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.337731\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.428065\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.222806\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.295138\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.199019\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.314758\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.457915\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.294736\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.281774\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.174980\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.493193\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.219386\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.400670\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.359527\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.400476\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.472138\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.147157\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.179479\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.256305\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.373204\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.220765\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.197869\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.276195\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.201120\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.284999\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.378619\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.254218\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.160615\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.218927\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.339550\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.409793\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.258700\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.328839\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.226662\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.288065\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.282729\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.226393\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.213063\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.189107\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.189262\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.176180\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.253623\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.363175\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.245519\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.304029\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.376394\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.258656\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.433557\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.200954\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.158061\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.118289\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.180400\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.190364\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.127363\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.273191\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.168872\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.156983\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.164927\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.234430\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.154886\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.522165\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.204316\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.259929\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.342577\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.233609\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.408955\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.125246\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.226752\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.180655\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.213447\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.271724\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.079196\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.305350\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.208145\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.304343\n",
      "\n",
      "Test set: Average loss: 0.0034, Accuracy: 9406/10000 (94%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.158115\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.262688\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.198356\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.211449\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.240284\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.411785\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.139965\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.269892\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.098303\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.079761\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.313322\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.144730\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.168489\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.067647\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.095863\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.112139\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.119324\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.354672\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.146636\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.302783\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.141053\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.168247\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.081273\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.151111\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.316393\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.250000\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.106085\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.308212\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.155225\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.152275\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.114591\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.102940\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.244182\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.110721\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.187040\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.152729\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.207513\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.270277\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.234977\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.214683\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.308483\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.247567\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.229658\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.127436\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.182246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.097395\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.131010\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.159790\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.180660\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.141791\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.244338\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.211598\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.173035\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.089460\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.179199\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.169627\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.201442\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.257080\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.074216\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.372234\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.214672\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.150263\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.278069\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.078030\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.075992\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.145131\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.179963\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.232420\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.261935\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.313634\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.326795\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.181212\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.177452\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.309000\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.303359\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.162167\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.147727\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.124201\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.157068\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.332990\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.222749\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.192729\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.173429\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.192289\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.100436\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.095474\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.187170\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.214922\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.212967\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.201968\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.118884\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.325952\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.132355\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.096864\n",
      "\n",
      "Test set: Average loss: 0.0027, Accuracy: 9505/10000 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.236128\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.429301\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.122877\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.136438\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.214585\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.122382\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.116354\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.191597\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.127007\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.119996\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.194829\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.091688\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.051453\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.156587\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.128995\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.144776\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.122321\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.181315\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.167428\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.087506\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.173636\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.280398\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.070807\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.158359\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.183418\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.176294\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.082659\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.073216\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.236053\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.153119\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.078198\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.169145\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.143106\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.206929\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.135549\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.152746\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.052667\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.210552\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.145269\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.188232\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.063280\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.179396\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.088170\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.109486\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.134803\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.109679\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.096734\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.236099\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.271918\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.147529\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.181241\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.373274\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.451783\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.064652\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.255680\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.093287\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.114323\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.158360\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.194536\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.068128\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.402404\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.113173\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.197881\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.074534\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.055783\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.104572\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.154503\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.282135\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.096709\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.079878\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.046270\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.183152\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.148737\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.190666\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.084417\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.259748\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.160960\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.037786\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.154117\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.230480\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.171692\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.104738\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.152095\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.312772\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.090624\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.259979\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.125409\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.210891\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.159797\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.064219\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.270054\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.084890\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.074767\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.099997\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9597/10000 (95%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.189632\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.151068\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.092181\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.140110\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.139473\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.070755\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.148262\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.134607\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.053061\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.167976\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.044720\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.051144\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.351830\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.188997\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.215861\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.057207\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.151158\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.149155\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.110743\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.120446\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.055240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.186456\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.091084\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.140484\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.042278\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.023526\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.092729\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.166856\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.064776\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.104486\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.060486\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.109730\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.113638\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.192605\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.170918\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.192656\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.209279\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.117468\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.063208\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.158214\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.047568\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.035981\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.125263\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.158945\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.162292\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.138584\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.045787\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.064148\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.069852\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.075920\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.122521\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.133917\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.181228\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.249210\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.124160\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.135467\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.110377\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.062647\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.220148\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.102718\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.083567\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.180125\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.138683\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.114380\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.137717\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.099635\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.309366\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.156005\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.104589\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.097994\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.258147\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.131581\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.114836\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.079808\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.089535\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.097238\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.100174\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.090695\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.063725\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.057261\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.112524\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.281605\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.151620\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.140132\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.180905\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.258320\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.240783\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.045349\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.062685\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.179436\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.177501\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.115367\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.100838\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.099651\n",
      "\n",
      "Test set: Average loss: 0.0020, Accuracy: 9619/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.035344\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.090525\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.091017\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.136849\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.088928\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.058318\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.177278\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.107377\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.269370\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.097836\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.039684\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.179231\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.167068\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.288219\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.116918\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.037277\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.371833\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.074947\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.093200\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.155506\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.257701\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.223845\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.211538\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.045970\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.129779\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.074904\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.229361\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.178482\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.052147\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.109602\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.048998\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.176701\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.153649\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.070933\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.026897\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.077247\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.158430\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.026583\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.087840\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.074245\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.094549\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.177510\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.046984\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.144025\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.048205\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.058141\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.059147\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.081703\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.100005\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.124504\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.084023\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.077840\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.099079\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.139881\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.055255\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.194138\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.047433\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.039930\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.071452\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.059215\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.051107\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.109755\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.144701\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.038088\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.076285\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.111657\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.255376\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.187109\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.044670\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.137903\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.116425\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.025786\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.046747\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.374555\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.042219\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.223043\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.063084\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.033386\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.111224\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.088224\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.281361\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.136751\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.063030\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.058125\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.131768\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.103973\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.205033\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.019518\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.134406\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.127833\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.093309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.043191\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.097479\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.140108\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 9633/10000 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.031398\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.236865\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.095129\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.125346\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.074211\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.059053\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.148445\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.237028\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.080717\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.060065\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.148942\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.107895\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.033600\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.074096\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.031444\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.019183\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.030414\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.059981\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.110287\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.075766\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.069509\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.042737\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.123017\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.083181\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.034039\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.114265\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.152747\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.050314\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.079653\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.064211\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.040172\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.114834\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.025998\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.168230\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.055930\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.134663\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.088724\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.092834\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.027424\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.145915\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.055202\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.048624\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.112898\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.114572\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.062554\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.095574\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.187843\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.195350\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.232574\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.099397\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.030980\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.037406\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.141950\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.053770\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.146847\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.178437\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.013029\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.072809\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.107545\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.124852\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.045590\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.056798\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.070471\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.175327\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.177541\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.144601\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.099027\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.078309\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.019848\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.167681\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.108299\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.048786\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.054571\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.074908\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.102580\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.051653\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.044309\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.047817\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.126908\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.122281\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.092568\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.041323\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.025880\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.059919\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.153815\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.074082\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.217723\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.051129\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.050909\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.098479\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.114584\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.024175\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.068843\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.068659\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 9696/10000 (96%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        output = model.forward(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval() # put in eval mode, no gradients\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(output, target).data[0]\n",
    "        # get the index of the max\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(model.state_dict(), './mnist_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo Exercise 9-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
